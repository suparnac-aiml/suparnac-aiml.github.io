{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175cb182-37e0-44af-91bf-4cbf3024a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b680b14-6339-420e-8152-16ef3234c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/suparnac/dev_envs/CV_Projects/satellite_image_classifier/EuroSAT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49b4519-d8e5-4184-b3fe-0e3297e02470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27002 files belonging to 10 classes.\n",
      "Using 21602 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 03:39:12.172726: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-07-08 03:39:12.172748: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-07-08 03:39:12.172750: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-07-08 03:39:12.172765: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-08 03:39:12.172773: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing the dataset\n",
    "# split the data into train and test/validation\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.2, # 80-20 dataset split\n",
    "    subset = \"training\", # specifies this dataset will be training subset and not the validation\n",
    "    seed = 123, #sets random seed for shuffling and splitting, ensuring reproducibility\n",
    "    image_size = (128, 128), #resize images intop 128x128 for easy processing\n",
    "    batch_size = 32 #groups images into batches of 32 for training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcf13c8-7f86-4548-8d75-e85f2bc7d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27002 files belonging to 10 classes.\n",
      "Using 5400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split =0.2,\n",
    "    subset =\"validation\", # previously it considered the dataset for the training, here it is assigning the data for validation\n",
    "    seed = 123,\n",
    "    image_size = (128, 128),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7045f4-9211-4bcd-8796-7ffd14fafd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' normalizing the images to range [0,1]\n",
    "need to normalize:  \n",
    "- stability and speed of training\n",
    "- consistent data range\n",
    "- improved model performance\n",
    "- compatibility with activation functions \n",
    "'''\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255) # rescaling layer from the keras API\n",
    "# map() applies function to each element (batch) in the dataset\n",
    "train_dataset = train_dataset.map(lambda x,y: (normalization_layer(x), y)) # x - here images , y - here labels \n",
    "validation_dataset = validation_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa29d865-35ed-415e-87ec-86c4f3194272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model using transfer learning\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape = (128,128,3), include_top= False, weights='imagenet')\n",
    "\n",
    "''' input shape = 128,128, 3 --- 3 here is the 3 color channels (RGB)\n",
    "include_top = False --- determines whether to include the fully connected layers (the \"top\") layers of the original model (here MobileNetV2)\n",
    "weights = 'imagenet', (pre-trained weights from ImageNet) Loads pre-trained weights from training on the ImageNet dataset.\n",
    "ImageNet is a large visual database. The model initializes with weights learned from the large-scale ImageNet dataset.\n",
    "'''\n",
    "\n",
    "base_model.trainable = False #the pre-trained MobileNetV2 model will not be updated during training. Its weights will remain fixed (frozen), and only the additional layers added afterward will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5741d038-69fe-4140-9e75-e698c247274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [base_model, # above trined base_model using MobileNetV2\n",
    "     tf.keras.layers.GlobalAveragePooling2D(), # Reduces each feature map to a single value by averaging, converting the output into a 1D vector.\n",
    "     tf.keras.layers.Dense(128, activation = 'relu'), #Adds a fully connected layer with 128 neurons and ReLU activation, introducing non-linearity.\n",
    "     tf.keras.layers.Dense(10, activation = 'softmax') #Adds an output layer with 10 neurons (for 10 classes) using softmax activation to produce probability scores for each class.\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bb12c0-dc20-4ef9-8dc2-2b537058b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', #Adam(Adaptive Moment Estimation)--optimizer algorithm adjusts a neural network's weights during training to minimize the errors(loss),  \n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "655240b1-ae47-4ce0-96ae-33362104ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 03:40:23.642133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7963 - loss: 0.6104\n",
      "Epoch 2/5\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.8942 - loss: 0.3115\n",
      "Epoch 3/5\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 35ms/step - accuracy: 0.9056 - loss: 0.2731\n",
      "Epoch 4/5\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 35ms/step - accuracy: 0.9048 - loss: 0.2753\n",
      "Epoch 5/5\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 35ms/step - accuracy: 0.9002 - loss: 0.3129\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "training_history = model.fit(train_dataset, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ca6ce3-63c8-4bdf-bd2b-2d209103f603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "\n",
    "model.save(\"satellite_classifier_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65576496-e5ba-4741-99bc-fc1290f9be80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv_env)",
   "language": "python",
   "name": "cv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
